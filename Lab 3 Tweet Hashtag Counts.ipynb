{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DS/CMPSC 410 Sparing 2021\n",
    "## Instructor: Professor John Yen\n",
    "## TA: Rupesh Prajapati and Dongkuan Xu\n",
    "## Lab 3: Filtering and Top Hashtags/Twitters in Tweets\n",
    "## The goals of this lab are for you to be able to\n",
    "- Implement filtering in a data stream in Spark\n",
    "- Reverse a key-value pair \n",
    "- Sort a Key Value Pairs RDD by keys\n",
    "- Filter a Key Value Pairs RDD (by key)\n",
    "- Apply the above to find top hashtags in a set of tweets\n",
    "\n",
    "## Total Number of Exercises: \n",
    "- Exercise 1: 5 points\n",
    "- Exercise 2: 10 points\n",
    "- Exercise 3: 15 points\n",
    "## Total Points: 30 points\n",
    "\n",
    "# Due: midnight, February 7, 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The first thing we need to do in each Jupyter Notebook running pyspark is to import pyspark first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Once we import pyspark, we need to import an important object called \"SparkContext\".  Every spark program needs a SparkContext object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We then create a Spark Context variable.  Once we have a spark context variable, we can execute spark codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://comp-sc-0238.acib.production.int.aci.ics.psu.edu:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Lab3</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local appName=Lab3>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc=SparkContext(\"local\", \"Lab3\")\n",
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1 (5 points) (a) Add your name below AND (b) replace the path below with the path of your home directory.\n",
    "## Answer for Exercise 1\n",
    "- a: Your Name: Hanzhong Ye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/storage/home/hjy5082/DS410Lab3/TweetsClimateChangeSentiment.csv MapPartitionsRDD[1] at textFile at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_RDD = sc.textFile(\"/storage/home/hjy5082/DS410Lab3/TweetsClimateChangeSentiment.csv\")\n",
    "text_RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[2] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_RDD = text_RDD.flatMap(lambda line: line.strip().split(' '))\n",
    "token_RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[2] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_RDD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering an RDD\n",
    "\n",
    "## The syntax for filter (one type of data trasnformation in spark) is\n",
    "## RDD.filter(lambda parameter : condition ) ##\n",
    "## Notice the syntax is not what is described in p. 38 of the textbook.\n",
    "##  The result of filtering the input RDD is the collection of all elements that pass the filter condition (i.e., returns True when the filtering condition is applied to the parameter. \n",
    "## For example, the filtering condition in the pyspark conde below checks whether each element of the input RDD (i.e., token_RDD) starts with the character \"#\", using Python startswith() method for string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[3] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashtag_RDD = token_RDD.filter(lambda token : token.startswith(\"#\"))\n",
    "hashtag_RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[4] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashtag_count_RDD = hashtag_RDD.map(lambda hashtag: (hashtag, 1))\n",
    "hashtag_count_RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[9] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashtag_total_RDD = hashtag_count_RDD.reduceByKey(lambda a, b: a + b, 1)\n",
    "hashtag_total_RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[10] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_hashtag_RDD = hashtag_total_RDD.map(lambda x: tuple(reversed(x)) )\n",
    "total_hashtag_RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[11] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_total_hashtag_RDD = total_hashtag_RDD.sortByKey(ascending=False)\n",
    "sorted_total_hashtag_RDD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 (10 points) Complete the code below to obtain hashtags that occured at least n time in this set of tweets. You can choose n to be any integer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "top_count2_hashtags_RDD = sorted_total_hashtag_RDD.filter(lambda x: x[0]>=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(81, '#climatechange'),\n",
       " (45, '#ClimateChange'),\n",
       " (16, '#IPCC'),\n",
       " (14, '#HurricaneMichael'),\n",
       " (13, '#GlobalWarming'),\n",
       " (12, '#auspol'),\n",
       " (10, '#science')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_count2_hashtags_RDD.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 (15 points) \n",
    "Complete pyspark code below to \n",
    "- (a) Compute total counts of all hashtags in the vaccination_tweets (5 points)\n",
    "- (b) Sort the count of hashtags in descending order. (5 points)\n",
    "- (c) Save all hashtags that have occured at least 10 times. (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for Exercise 3: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/storage/home/hjy5082/DS410Lab3/vaccination_tweets_2.csv MapPartitionsRDD[16] at textFile at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2_RDD = sc.textFile(\"/storage/home/hjy5082/DS410Lab3/vaccination_tweets_2.csv\")\n",
    "text2_RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[17] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token2_RDD = text2_RDD.flatMap(lambda line: line.strip().split(\" \"))\n",
    "token2_RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[18] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashtag2_RDD = token2_RDD.filter(lambda token : token.startswith(\"#\"))\n",
    "hashtag2_RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[19] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashtag_count2_RDD = hashtag2_RDD.map(lambda hashtag: (hashtag, 1))\n",
    "hashtag_count2_RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[24] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashtag_total2_RDD = hashtag_count2_RDD.reduceByKey(lambda a, b: a + b, 1)\n",
    "hashtag_total2_RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[25] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_hashtag2_RDD = hashtag_total2_RDD.map(lambda x: tuple(reversed(x)) )\n",
    "total_hashtag2_RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[26] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_total2_hashtag_RDD = total_hashtag2_RDD.sortByKey(ascending=False)\n",
    "sorted_total2_hashtag_RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2024, '#PfizerBioNTech'),\n",
       " (480, '#COVID19'),\n",
       " (333, '#vaccine'),\n",
       " (317, '#CovidVaccine'),\n",
       " (189, '#Pfizer'),\n",
       " (133, '#PfizerBioNTechâ€¦'),\n",
       " (125, '#Moderna'),\n",
       " (111, '#coronavirus'),\n",
       " (96, '#PfizerVaccine'),\n",
       " (73, '#vaccination'),\n",
       " (68, '#Covid19'),\n",
       " (67, '#AstraZeneca'),\n",
       " (64, '#Pfizervaccine'),\n",
       " (61, '#vaccines'),\n",
       " (55, '#NHS'),\n",
       " (53, '#COVID19Vaccine'),\n",
       " (50, '#COVID19â€¦'),\n",
       " (48, '#PfizerCovidVaccine'),\n",
       " (48, '#BLM'),\n",
       " (47, '#Pfizerâ€¦'),\n",
       " (46, '#Vaccine'),\n",
       " (44, '#Covid_19'),\n",
       " (41, '#COVIDVaccination'),\n",
       " (37, '#Diabetes'),\n",
       " (35, '#ItsNotJustCovid'),\n",
       " (35, '#ContinuityOfCare'),\n",
       " (35, '#3.5%'),\n",
       " (34, '#FBPE,Cornwall'),\n",
       " (34, '#RejoinEU,'),\n",
       " (34, '#ProEU'),\n",
       " (34, '#GTTO\",7/18/11'),\n",
       " (33, '#covid19'),\n",
       " (31, '#BioNTech'),\n",
       " (30, '#vaccinated'),\n",
       " (28, '#vaccineâ€¦'),\n",
       " (28, '#Dubai'),\n",
       " (27, '#pfizerbiontech'),\n",
       " (26, '#EU'),\n",
       " (26, '#Israel'),\n",
       " (26, '#news'),\n",
       " (25, '#PatientsAtTheCentre'),\n",
       " (24, '#Iran'),\n",
       " (24, '#CovidVaccineâ€¦'),\n",
       " (24, '#UK'),\n",
       " (24, '#mRNA'),\n",
       " (24, '#COVID'),\n",
       " (23, '#2'),\n",
       " (23, '#Canada'),\n",
       " (23, '#FBPE'),\n",
       " (23, '#RejoinEU'),\n",
       " (22, '#oxfordastrazeneca'),\n",
       " (21, '#CoronavirusVaccine'),\n",
       " (21, '#COVID19vaccine'),\n",
       " (21, '#CoronaVaccine'),\n",
       " (19, '#US'),\n",
       " (19, '#covid'),\n",
       " (19, '#Qatar'),\n",
       " (19, '#modernavaccine'),\n",
       " (19, '#covidvaccines'),\n",
       " (19, '#Norway'),\n",
       " (18, '#VaccinesWork'),\n",
       " (18, '#1'),\n",
       " (18, '#PfizerVaccineâ€¦'),\n",
       " (17, \"#PfizerBioNTech's\"),\n",
       " (17, \"#PfizerBioNTech,['PfizerBioNTech'],Twitter\"),\n",
       " (17, '#Asia'),\n",
       " (17, '#PfizerCOVIDvaccine'),\n",
       " (16, '#Doha,7/25/09'),\n",
       " (16, '#WHO'),\n",
       " (15, '#technology'),\n",
       " (15, '#PfizerBioNTech.'),\n",
       " (15, '#Sinovac'),\n",
       " (15, '#tech'),\n",
       " (15, '#covidvacccine'),\n",
       " (15, '#COVIDvaccines'),\n",
       " (15, '#GTTO,,\"With'),\n",
       " (14, '#coronavirusâ€¦'),\n",
       " (14, '#COVIDãƒ¼19'),\n",
       " (14, '#Emirati'),\n",
       " (14, '#Politics'),\n",
       " (13, '#SARSCoV2'),\n",
       " (13, '#FDA'),\n",
       " (13, '#HumanRights'),\n",
       " (13, '#Coronavirus'),\n",
       " (13, '#digital'),\n",
       " (13, '#Modernaâ€¦'),\n",
       " (13, '#counterTerrorism,'),\n",
       " (13, '#Ø§Ù„Ù„Ù‡_Ø«Ù…_Ø§Ù„ÙˆØ·Ù†_Ø«Ù…_Ø±Ø¦ÙŠØ³_Ø§Ù„Ø¯ÙˆÙ„Ø©'),\n",
       " (13, '#Covid'),\n",
       " (13, '#vaccinations'),\n",
       " (13, '#vaccines.â€¦'),\n",
       " (12, '#SputnikV'),\n",
       " (12, '#Pfizervaccineâ€¦'),\n",
       " (12, '#vaccine,'),\n",
       " (12, '#healthcare'),\n",
       " (12, '#FMcy\",9/29/10'),\n",
       " (12, '#Chronoptimist'),\n",
       " (12, '#TeamGPðŸ’™Trainer'),\n",
       " (12, '#Covid19UK'),\n",
       " (12, '#vaccine.'),\n",
       " (12, '#USA'),\n",
       " (12, '#COVID20'),\n",
       " (12, '#Vaccin'),\n",
       " (12, '#PfizerBioNTech,'),\n",
       " (12, '#OxfordVaccine'),\n",
       " (12, '#FBPEðŸ‡ªðŸ‡ºðŸ‡¬ðŸ‡§ðŸ‡­ðŸ‡º,Earth,\"\"\"It'),\n",
       " (12, '#History'),\n",
       " (12, '#ElectoralReform'),\n",
       " (12, '#WHUFC\",9/22/17'),\n",
       " (11, '#oxfordvaccine'),\n",
       " (11, '#Turkey'),\n",
       " (11, '#littleBRIC:'),\n",
       " (11, '#GetVaccinated'),\n",
       " (11, '#PfizerBioNTech\",[\\'PfizerBioNTech\\'],Twitter'),\n",
       " (10, '#PfizerBioNtech'),\n",
       " (10, '#CovidVaccines'),\n",
       " (10, '#VaccinesSaveLives'),\n",
       " (10, '#Twinja\",10/6/14'),\n",
       " (10, '#Covid19Vaccine'),\n",
       " (10, '#Science'),\n",
       " (10, '#CoronavirusPandemic'),\n",
       " (10, '#covidvaccine'),\n",
       " (10, '#PfizerBioNTech,\"[\\'CovidVaccine\\','),\n",
       " (10, '#nhs'),\n",
       " (10, '#vaccines.Thiâ€¦'),\n",
       " (10, '#vaccinationCovid')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_count2_hashtag_RDD = sorted_total2_hashtag_RDD.filter(lambda x: x[0] >= 10 )\n",
    "top_count2_hashtag_RDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"/storage/home/hjy5082/DS410Lab3/Lab3_ouput_top_hashtag.txt\"\n",
    "top_count2_hashtag_RDD.saveAsTextFile(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
